{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import CTCLoss, Linear, Module, LSTM, Conv1d, ReLU, Dropout#, LogSoftmax\n",
    "from torch.nn.functional import log_softmax, softmax\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "from time import time\n",
    "from Levenshtein import distance\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "N_PHONEMES = 41\n",
    "PHONEME_LIST = [\n",
    "    \" \",\n",
    "    \"SIL\",\n",
    "    \"SPN\",\n",
    "    \"AA\",\n",
    "    \"AE\",\n",
    "    \"AH\",\n",
    "    \"AO\",\n",
    "    \"AW\",\n",
    "    \"AY\",\n",
    "    \"B\",\n",
    "    \"CH\",\n",
    "    \"D\",\n",
    "    \"DH\",\n",
    "    \"EH\",\n",
    "    \"ER\",\n",
    "    \"EY\",\n",
    "    \"F\",\n",
    "    \"G\",\n",
    "    \"H\",\n",
    "    \"IH\",\n",
    "    \"IY\",\n",
    "    \"JH\",\n",
    "    \"K\",\n",
    "    \"L\",\n",
    "    \"M\",\n",
    "    \"N\",\n",
    "    \"NG\",\n",
    "    \"OW\",\n",
    "    \"OY\",\n",
    "    \"P\",\n",
    "    \"R\",\n",
    "    \"S\",\n",
    "    \"SH\",\n",
    "    \"T\",\n",
    "    \"TH\",\n",
    "    \"UH\",\n",
    "    \"UW\",\n",
    "    \"V\",\n",
    "    \"W\",\n",
    "    \"Y\",\n",
    "    \"Z\",\n",
    "    \"ZH\"\n",
    "]\n",
    "# PHONEME_LIST.append('')\n",
    "\n",
    "PHONEME_MAP = [\n",
    "    \" \",\n",
    "    \".\", #SIL\n",
    "    \"!\", #SPN\n",
    "    \"a\", #AA\n",
    "    \"A\", #AE\n",
    "    \"h\", #AH\n",
    "    \"o\", #AO\n",
    "    \"w\", #AW\n",
    "    \"y\", #AY\n",
    "    \"b\", #B\n",
    "    \"c\", #CH\n",
    "    \"d\", #D\n",
    "    \"D\", #DH\n",
    "    \"e\", #EH\n",
    "    \"r\", #ER\n",
    "    \"E\", #EY\n",
    "    \"f\", #F\n",
    "    \"g\", #G\n",
    "    \"H\", #H\n",
    "    \"i\", #IH \n",
    "    \"I\", #IY\n",
    "    \"j\", #JH\n",
    "    \"k\", #K\n",
    "    \"l\", #L\n",
    "    \"m\", #M\n",
    "    \"n\", #N\n",
    "    \"N\", #NG\n",
    "    \"O\", #OW\n",
    "    \"Y\", #OY\n",
    "    \"p\", #P \n",
    "    \"R\", #R\n",
    "    \"s\", #S\n",
    "    \"S\", #SH\n",
    "    \"t\", #T\n",
    "    \"T\", #TH\n",
    "    \"u\", #UH\n",
    "    \"U\", #UW\n",
    "    \"v\", #V\n",
    "    \"W\", #W\n",
    "    \"?\", #Y\n",
    "    \"z\", #Z\n",
    "    \"Z\" #ZH\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X_path, Y_path=None):\n",
    "        self.X = np.load(X_path, allow_pickle=True)\n",
    "        if Y_path:\n",
    "            self.Y = np.load(Y_path, allow_pickle=True)\n",
    "        else:\n",
    "            self.Y=None\n",
    "        self.length = self.X.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        if self.Y!=None:\n",
    "            Y = self.Y[index] # to make sure 0 is reserved for blank\n",
    "            return torch.DoubleTensor(X), torch.DoubleTensor(Y)+1, torch.LongTensor([X.shape[0]]), torch.LongTensor([Y.shape[0]]) # may have to do .float()/.long()\n",
    "        else:\n",
    "            return torch.DoubleTensor(X), torch.LongTensor([X.shape[0]])\n",
    "class TestCollateFunction(object):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    def __call__(self, batch):\n",
    "        X = []\n",
    "        X_len = []\n",
    "        for tup in batch:\n",
    "            X.append(tup[0])\n",
    "            X_len.append(tup[1])\n",
    "        # X = torch.stack(X, 0) # stack?                 NEED TO SEPARATE, NO CAT\n",
    "        # Y = torch.stack(Y,0)\n",
    "        X = pad_sequence(X)\n",
    "        X = X.permute(1,2,0)\n",
    "        X_len = torch.cat(X_len,0).long()\n",
    "        return X, X_len\n",
    "    \n",
    "class CollateFunction(object):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    def __call__(self, batch):\n",
    "        X = []\n",
    "        Y = []\n",
    "        X_len = []\n",
    "        Y_len = []\n",
    "        for tup in batch:\n",
    "            X.append(tup[0])\n",
    "            Y.append(tup[1])\n",
    "            X_len.append(tup[2])\n",
    "            Y_len.append(tup[3])\n",
    "        # X = torch.stack(X, 0) # stack?                 NEED TO SEPARATE, NO CAT\n",
    "        # Y = torch.stack(Y,0)\n",
    "        X = pad_sequence(X)\n",
    "        X = X.permute(1,2,0)\n",
    "        Y = pad_sequence(Y).permute(1,0) # Batch X \n",
    "        X_len = torch.cat(X_len,0)#.long()\n",
    "        Y_len = torch.cat(Y_len,0)#.long()\n",
    "        return X, Y, X_len, Y_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "dev_path = 'dev.npy'\n",
    "dev_labels_path = 'dev_labels.npy'\n",
    "val_dataset = MyDataset(dev_path, dev_labels_path)\n",
    "\n",
    "train_path = 'train.npy'\n",
    "train_labels_path = 'train_labels.npy'\n",
    "train_dataset = MyDataset(train_path, train_labels_path)\n",
    "\n",
    "cuda = True\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\") \n",
    "numworkers = 4 if cuda else 0\n",
    "batchsize = 64 if cuda else 64\n",
    "\n",
    "collatefn = CollateFunction()\n",
    "val_loader_args = dict(shuffle=False, batch_size=batchsize, num_workers=numworkers, pin_memory=True, collate_fn=collatefn) if cuda else dict(shuffle=False, batch_size=batchsize, collate_fn=collatefn)\n",
    "val_loader = DataLoader(val_dataset, **val_loader_args)\n",
    "\n",
    "train_loader_args = dict(shuffle=True, batch_size=batchsize, num_workers=numworkers, pin_memory=True, collate_fn=collatefn) if cuda else dict(shuffle=True, batch_size=batchsize, collate_fn=collatefn)\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args)\n",
    "\n",
    "print('Data Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('.mistrkWiltrizDIhpashlhvDhmidhlklAshz.hndWIrglAdtUWelkhmHizgasphl.',\n",
       " tensor([ 1., 24., 19., 31., 33., 14., 22., 38., 19., 23., 33., 14., 19., 40.,\n",
       "         12., 20.,  5., 29.,  3., 31.,  5., 23.,  5., 37., 12.,  5., 24., 19.,\n",
       "         11.,  5., 23., 22., 23.,  4., 31.,  5., 40.,  1.,  5., 25., 11., 38.,\n",
       "         20., 14., 17., 23.,  4., 11., 33., 36., 38., 13., 23., 22.,  5., 24.,\n",
       "         18., 19., 40., 17.,  3., 31., 29.,  5., 23.,  1.], dtype=torch.float64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAL_ROWS = []\n",
    "for i in range(len(val_dataset)):\n",
    "#     print(val_dataset[i][1],val_dataset[i][3].item())\n",
    "    row=''\n",
    "    for j in range(val_dataset[i][3].item()):\n",
    "        row += PHONEME_MAP[val_dataset[i][1][j].long().item()]\n",
    "    VAL_ROWS.append(row)\n",
    "VAL_ROWS[0], val_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('.mistrkWiltrizDIhpashlhvDhmidhlklAshz.hndWIrglAdtUWelkhmHizgasphl.',\n",
    "#  tensor([ 0., 24.,  5., 29., 18., 39., 23., 18., 30., 32., 13.,  1., 23.,  3.,\n",
    "#          24., 13., 22., 12., 30., 18., 24., 32., 13.,  4., 30., 32., 18., 25.,\n",
    "#          11.,  4., 24., 17., 18., 39., 23.,  3., 32., 13.,  0.],\n",
    "#         dtype=torch.float64))\n",
    "test_path = 'test.npy'\n",
    "test_dataset = MyDataset(test_path)\n",
    "testcollatefn = TestCollateFunction()\n",
    "test_loader_args = dict(shuffle=False, batch_size=batchsize, num_workers=numworkers, pin_memory=True, collate_fn=testcollatefn) if cuda else dict(shuffle=False, batch_size=batchsize, collate_fn=testcollatefn)\n",
    "test_loader = DataLoader(test_dataset, **test_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "# Model_5, Model_2 without 4th LSTM\n",
    "# class Model(Module):\n",
    "#     def __init__(self, out_vocab, embed_size, hidden_size, in_channel=13):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.conv1d = Conv1d(in_channel, embed_size, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.lstm1 = LSTM(embed_size, hidden_size, bidirectional=True)\n",
    "#         self.lstm2 = LSTM(hidden_size*2, hidden_size, bidirectional=True)\n",
    "#         self.lstm3 = LSTM(hidden_size*2, hidden_size, bidirectional=True)\n",
    "# #         self.lstm4 = LSTM(hidden_size*2, hidden_size, bidirectional=True)\n",
    "#         self.predict = False\n",
    "        \n",
    "# #         self.linear1 = Linear(hidden_size*2, hidden_size*2)\n",
    "# #         self.relu1 = ReLU()\n",
    "# #         self.linear2 = Linear(hidden_size*2, out_vocab+1)\n",
    "        \n",
    "#         self.linear3 = Linear(hidden_size*2, out_vocab+1)\n",
    "        \n",
    "#     def forward(self, X, X_lens):\n",
    "#         X = self.conv1d(X) # CNN requires (batch_size, embedding_size, timesteps)\n",
    "\n",
    "#         X = X.permute(0,2,1)\n",
    "#         packed_X = pack_padded_sequence(X, X_lens, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "#         packed_X = self.lstm1(packed_X)[0] # LSTM requires (timesteps, batch_size, embedding_size)\n",
    "#         packed_X = self.lstm2(packed_X)[0]\n",
    "#         packed_X = self.lstm3(packed_X)[0]\n",
    "# #         packed_X = self.lstm4(packed_X)[0]\n",
    "        \n",
    "#         X, out_lens = pad_packed_sequence(packed_X)\n",
    "        \n",
    "# #         X = self.linear1(X.permute(1,0,2))\n",
    "# #         X = self.relu1(X)\n",
    "# #         out = self.linear2(X).softmax(2) # B x timesteps x 42 log_softmax(2)\n",
    "        \n",
    "#         X = self.linear3(X.permute(1,0,2))\n",
    "        \n",
    "# #         if self.predict:\n",
    "# #             print(\"SOFTMAX\")\n",
    "# #         out = X.softmax(2)\n",
    "# #         else:\n",
    "# #             print(\"LOG\")\n",
    "#         out = X.log_softmax(2)\n",
    "        \n",
    "#         return out, out_lens\n",
    "\n",
    "# Model_6\n",
    "class Model(Module):\n",
    "    def __init__(self, out_vocab, embed_size, hidden_size, in_channel=13):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1d1 = Conv1d(in_channel, embed_size, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.lstm1 = LSTM(embed_size, hidden_size, bidirectional=True)\n",
    "        self.conv1d2 = Conv1d(hidden_size*2, hidden_size*2, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.lstm2 = LSTM(hidden_size*2, hidden_size, bidirectional=True)\n",
    "        self.lstm3 = LSTM(hidden_size*2, hidden_size, bidirectional=True)\n",
    "        self.predict = False\n",
    "        \n",
    "#         self.linear1 = Linear(hidden_size*2, hidden_size*2)\n",
    "#         self.relu1 = ReLU()\n",
    "#         self.linear2 = Linear(hidden_size*2, out_vocab+1)\n",
    "        \n",
    "        self.linear3 = Linear(hidden_size*2, out_vocab+1)\n",
    "        \n",
    "    def forward(self, X, X_lens):\n",
    "        X = self.conv1d1(X) # CNN requires (batch_size, embedding_size, timesteps)\n",
    "        X = X.permute(0,2,1)\n",
    "        packed_X = pack_padded_sequence(X, X_lens, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        packed_X = self.lstm1(packed_X)[0] # LSTM requires (timesteps, batch_size, embedding_size)\n",
    "        \n",
    "        X, X_lens = pad_packed_sequence(packed_X)\n",
    "        \n",
    "        X = X.permute(1,2,0)\n",
    "        X = self.conv1d2(X)\n",
    "        X = X.permute(0,2,1)\n",
    "        packed_X = pack_padded_sequence(X, X_lens, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        packed_X = self.lstm2(packed_X)[0]\n",
    "        packed_X = self.lstm3(packed_X)[0]\n",
    "        \n",
    "        X, out_lens = pad_packed_sequence(packed_X)\n",
    "        X = self.linear3(X.permute(1,0,2))\n",
    "        out = X.log_softmax(2)\n",
    "        return out, out_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False tensor([[[-3.7687, -3.7972, -3.7302,  ..., -3.7418, -3.7511, -3.7313],\n",
      "         [-3.7724, -3.8035, -3.7303,  ..., -3.7439, -3.7476, -3.7318],\n",
      "         [-3.7751, -3.8070, -3.7299,  ..., -3.7458, -3.7451, -3.7322],\n",
      "         ...,\n",
      "         [-3.7793, -3.8041, -3.7310,  ..., -3.7514, -3.7432, -3.7348],\n",
      "         [-3.7769, -3.8003, -3.7312,  ..., -3.7515, -3.7448, -3.7357],\n",
      "         [-3.7723, -3.7965, -3.7312,  ..., -3.7495, -3.7470, -3.7362]],\n",
      "\n",
      "        [[-3.7688, -3.7965, -3.7302,  ..., -3.7405, -3.7515, -3.7319],\n",
      "         [-3.7730, -3.8025, -3.7307,  ..., -3.7427, -3.7487, -3.7323],\n",
      "         [-3.7765, -3.8059, -3.7307,  ..., -3.7451, -3.7465, -3.7323],\n",
      "         ...,\n",
      "         [-3.7796, -3.8041, -3.7296,  ..., -3.7515, -3.7417, -3.7359],\n",
      "         [-3.7773, -3.8004, -3.7299,  ..., -3.7512, -3.7434, -3.7368],\n",
      "         [-3.7727, -3.7966, -3.7302,  ..., -3.7489, -3.7459, -3.7372]],\n",
      "\n",
      "        [[-3.7673, -3.7964, -3.7312,  ..., -3.7412, -3.7512, -3.7315],\n",
      "         [-3.7710, -3.8025, -3.7316,  ..., -3.7432, -3.7478, -3.7316],\n",
      "         [-3.7738, -3.8057, -3.7314,  ..., -3.7453, -3.7453, -3.7314],\n",
      "         ...,\n",
      "         [-3.7782, -3.8026, -3.7307,  ..., -3.7508, -3.7419, -3.7357],\n",
      "         [-3.7760, -3.7991, -3.7308,  ..., -3.7507, -3.7439, -3.7366],\n",
      "         [-3.7717, -3.7956, -3.7310,  ..., -3.7490, -3.7465, -3.7374]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.7672, -3.7954, -3.7312,  ..., -3.7406, -3.7517, -3.7314],\n",
      "         [-3.7707, -3.8013, -3.7320,  ..., -3.7420, -3.7486, -3.7319],\n",
      "         [-3.7738, -3.8051, -3.7320,  ..., -3.7437, -3.7459, -3.7318],\n",
      "         ...,\n",
      "         [-3.7779, -3.8024, -3.7309,  ..., -3.7508, -3.7429, -3.7373],\n",
      "         [-3.7760, -3.7988, -3.7313,  ..., -3.7505, -3.7448, -3.7380],\n",
      "         [-3.7716, -3.7956, -3.7314,  ..., -3.7486, -3.7471, -3.7381]],\n",
      "\n",
      "        [[-3.7695, -3.7955, -3.7307,  ..., -3.7413, -3.7514, -3.7310],\n",
      "         [-3.7735, -3.8012, -3.7311,  ..., -3.7434, -3.7487, -3.7312],\n",
      "         [-3.7762, -3.8045, -3.7311,  ..., -3.7453, -3.7464, -3.7311],\n",
      "         ...,\n",
      "         [-3.7808, -3.8045, -3.7284,  ..., -3.7523, -3.7425, -3.7363],\n",
      "         [-3.7781, -3.8006, -3.7294,  ..., -3.7518, -3.7444, -3.7371],\n",
      "         [-3.7727, -3.7967, -3.7302,  ..., -3.7497, -3.7469, -3.7375]],\n",
      "\n",
      "        [[-3.7679, -3.7963, -3.7313,  ..., -3.7401, -3.7516, -3.7315],\n",
      "         [-3.7721, -3.8025, -3.7319,  ..., -3.7424, -3.7487, -3.7320],\n",
      "         [-3.7756, -3.8060, -3.7320,  ..., -3.7449, -3.7468, -3.7324],\n",
      "         ...,\n",
      "         [-3.7792, -3.8029, -3.7310,  ..., -3.7502, -3.7418, -3.7356],\n",
      "         [-3.7768, -3.7997, -3.7312,  ..., -3.7501, -3.7435, -3.7368],\n",
      "         [-3.7723, -3.7962, -3.7313,  ..., -3.7486, -3.7461, -3.7376]]],\n",
      "       grad_fn=<LogSoftmaxBackward>) torch.Size([32])\n",
      "True tensor([[[-3.7687, -3.7972, -3.7302,  ..., -3.7418, -3.7511, -3.7313],\n",
      "         [-3.7724, -3.8035, -3.7303,  ..., -3.7439, -3.7476, -3.7318],\n",
      "         [-3.7751, -3.8070, -3.7299,  ..., -3.7458, -3.7451, -3.7322],\n",
      "         ...,\n",
      "         [-3.7793, -3.8041, -3.7310,  ..., -3.7514, -3.7432, -3.7348],\n",
      "         [-3.7769, -3.8003, -3.7312,  ..., -3.7515, -3.7448, -3.7357],\n",
      "         [-3.7723, -3.7965, -3.7312,  ..., -3.7495, -3.7470, -3.7362]],\n",
      "\n",
      "        [[-3.7688, -3.7965, -3.7302,  ..., -3.7405, -3.7515, -3.7319],\n",
      "         [-3.7730, -3.8025, -3.7307,  ..., -3.7427, -3.7487, -3.7323],\n",
      "         [-3.7765, -3.8059, -3.7307,  ..., -3.7451, -3.7465, -3.7323],\n",
      "         ...,\n",
      "         [-3.7796, -3.8041, -3.7296,  ..., -3.7515, -3.7417, -3.7359],\n",
      "         [-3.7773, -3.8004, -3.7299,  ..., -3.7512, -3.7434, -3.7368],\n",
      "         [-3.7727, -3.7966, -3.7302,  ..., -3.7489, -3.7459, -3.7372]],\n",
      "\n",
      "        [[-3.7673, -3.7964, -3.7312,  ..., -3.7412, -3.7512, -3.7315],\n",
      "         [-3.7710, -3.8025, -3.7316,  ..., -3.7432, -3.7478, -3.7316],\n",
      "         [-3.7738, -3.8057, -3.7314,  ..., -3.7453, -3.7453, -3.7314],\n",
      "         ...,\n",
      "         [-3.7782, -3.8026, -3.7307,  ..., -3.7508, -3.7419, -3.7357],\n",
      "         [-3.7760, -3.7991, -3.7308,  ..., -3.7507, -3.7439, -3.7366],\n",
      "         [-3.7717, -3.7956, -3.7310,  ..., -3.7490, -3.7465, -3.7374]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.7672, -3.7954, -3.7312,  ..., -3.7406, -3.7517, -3.7314],\n",
      "         [-3.7707, -3.8013, -3.7320,  ..., -3.7420, -3.7486, -3.7319],\n",
      "         [-3.7738, -3.8051, -3.7320,  ..., -3.7437, -3.7459, -3.7318],\n",
      "         ...,\n",
      "         [-3.7779, -3.8024, -3.7309,  ..., -3.7508, -3.7429, -3.7373],\n",
      "         [-3.7760, -3.7988, -3.7313,  ..., -3.7505, -3.7448, -3.7380],\n",
      "         [-3.7716, -3.7956, -3.7314,  ..., -3.7486, -3.7471, -3.7381]],\n",
      "\n",
      "        [[-3.7695, -3.7955, -3.7307,  ..., -3.7413, -3.7514, -3.7310],\n",
      "         [-3.7735, -3.8012, -3.7311,  ..., -3.7434, -3.7487, -3.7312],\n",
      "         [-3.7762, -3.8045, -3.7311,  ..., -3.7453, -3.7464, -3.7311],\n",
      "         ...,\n",
      "         [-3.7808, -3.8045, -3.7284,  ..., -3.7523, -3.7425, -3.7363],\n",
      "         [-3.7781, -3.8006, -3.7294,  ..., -3.7518, -3.7444, -3.7371],\n",
      "         [-3.7727, -3.7967, -3.7302,  ..., -3.7497, -3.7469, -3.7375]],\n",
      "\n",
      "        [[-3.7679, -3.7963, -3.7313,  ..., -3.7401, -3.7516, -3.7315],\n",
      "         [-3.7721, -3.8025, -3.7319,  ..., -3.7424, -3.7487, -3.7320],\n",
      "         [-3.7756, -3.8060, -3.7320,  ..., -3.7449, -3.7468, -3.7324],\n",
      "         ...,\n",
      "         [-3.7792, -3.8029, -3.7310,  ..., -3.7502, -3.7418, -3.7356],\n",
      "         [-3.7768, -3.7997, -3.7312,  ..., -3.7501, -3.7435, -3.7368],\n",
      "         [-3.7723, -3.7962, -3.7313,  ..., -3.7486, -3.7461, -3.7376]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# block = BasicBlock(41, embed_size=256, hidden_size=512)\n",
    "# a = torch.rand((32,13,21)) # B,Ch,T\n",
    "# b = torch.ones((32))*21\n",
    "# out, out_len = block.forward(a,b)\n",
    "# out.shape, out_len.shape\n",
    "\n",
    "model = Model(41, embed_size=300, hidden_size=256)\n",
    "a = torch.rand((32,13,1650)) # B,Ch,T\n",
    "b = torch.ones((32))*1625\n",
    "out, out_len = model.forward(a,b)\n",
    "print(model.predict, out, out_len.shape)\n",
    "model.predict=True\n",
    "out, out_lens = model.forward(a,b)\n",
    "print(model.predict,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   39306 KB |   51626 KB |   72170 KB |   32864 KB |\n",
      "|       from large pool |   39008 KB |   51328 KB |   71872 KB |   32864 KB |\n",
      "|       from small pool |     298 KB |     298 KB |     298 KB |       0 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   39306 KB |   51626 KB |   72170 KB |   32864 KB |\n",
      "|       from large pool |   39008 KB |   51328 KB |   71872 KB |   32864 KB |\n",
      "|       from small pool |     298 KB |     298 KB |     298 KB |       0 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   86016 KB |   86016 KB |   86016 KB |       0 B  |\n",
      "|       from large pool |   83968 KB |   83968 KB |   83968 KB |       0 B  |\n",
      "|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   32373 KB |   34389 KB |   42718 KB |   10344 KB |\n",
      "|       from large pool |   30624 KB |   32640 KB |   40800 KB |   10176 KB |\n",
      "|       from small pool |    1749 KB |    1918 KB |    1918 KB |     168 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       7    |       8    |      10    |       3    |\n",
      "|       from large pool |       4    |       5    |       7    |       3    |\n",
      "|       from small pool |       3    |       3    |       3    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       7    |       8    |      10    |       3    |\n",
      "|       from large pool |       4    |       5    |       7    |       3    |\n",
      "|       from small pool |       3    |       3    |       3    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       6    |       6    |       6    |       0    |\n",
      "|       from large pool |       5    |       5    |       5    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       6    |       7    |       8    |       2    |\n",
      "|       from large pool |       5    |       6    |       7    |       2    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RUN_NUMBER = 6  # <============================= CHANGE THIS EVERY TIME ======================<<<<<<<<<\n",
    "# model = Model(41, embed_size=256, hidden_size=256).double().to(device)\n",
    "model_path = 'hw3p2_models/model_6_15/model.pt'\n",
    "model = torch.load(model_path).to(device)\n",
    "NUM_EPOCHS = 50\n",
    "learning_rate = (1e-3)/4 #\n",
    "mile_stones = [2+2,10,16,22] # [6,12,18,24,30]  # 2 model training: [5,15,20,25,30,35,40,45] \n",
    "gamma = 0.5\n",
    "# optimizer = optim.SGD(model.parameters(), momentum=0.9, weight_decay=5e-5, lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-6)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=mile_stones, gamma=gamma)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=2, verbose=True)\n",
    "criterion = CTCLoss()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def save_state(distance, running_best, model_number, model, train_loader_args, device, NUM_EPOCHS, learning_rate, optimizer, criterion):\n",
    "    path = './hw3p2_models/model_' + str(RUN_NUMBER) + '_'+str(model_number)\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    torch.save(model, path+'/model.pt')\n",
    "    # write parameter tracking file\n",
    "    parameter_file = open(path+'/hyperparameters.txt', 'w')\n",
    "    parameter_file.write('\\nLevenshtein Distance:\\n' + str(distance))\n",
    "    parameter_file.write('\\nRunning Best Levenshtein Distance:\\n' + str(running_best[0]) + \"  \" + str(running_best[1]))\n",
    "    parameter_file.write('\\nModel:\\n' + str(model))\n",
    "    parameter_file.write('\\ntrain_loader_args:\\n' + str(train_loader_args))\n",
    "    parameter_file.write('\\nDevice:\\n' + str(device))\n",
    "    parameter_file.write('\\nNUM_EPOCHS:\\n' + str(NUM_EPOCHS))\n",
    "    parameter_file.write('\\nLearning Rate:\\n' + str(learning_rate))\n",
    "    parameter_file.write('\\nOptimizer:\\n' + str(optimizer))\n",
    "    parameter_file.write('\\nCriterion:\\n' + str(criterion))\n",
    "    parameter_file.close()\n",
    "    \n",
    "def log(file,string):\n",
    "    file.write(string)\n",
    "    return\n",
    "# CTCDecode: https://github.com/parlance/ctcdecode\n",
    "# for decoder must make sure the labels list is the same length as out_vocab (or in my case out_vocab+1)\n",
    "# when discussing must make sure people understand that the ' ' character is the blank we are trying to account for\n",
    "def get_decoder(labels, beam=10):\n",
    "    return CTCBeamDecoder(labels, beam_width=beam, log_probs_input=True)\n",
    "\n",
    "def predict(model, loader, labels, decoder=None, test=False):\n",
    "    log_file = open(\"predict_decoder_logs.txt\", \"w\")\n",
    "    \n",
    "    if not decoder:\n",
    "        decoder = get_decoder(labels, beam=150)\n",
    "    model.eval()\n",
    "    model.predict = True\n",
    "    sequences = []\n",
    "    sequence_lens = []\n",
    "    if test:\n",
    "        for i, (x, x_len) in enumerate(loader):\n",
    "#             x_len.to(device)\n",
    "\n",
    "            output, out_lens = model(x.to(device), x_len)\n",
    "#             output = output.permute(1,0,2)\n",
    "\n",
    "            log_string = 'output:' + str(output.shape) + str(output) + '\\n' + 'out_lens: ' + str(out_lens.shape) + str(out_lens)\n",
    "            log(log_file, log_string)\n",
    "\n",
    "            # probabilities, out_lens are passed to ctcdecoder instead of loss\n",
    "            beam_results, beam_scores, timesteps, out_lens = decoder.decode(output, out_lens)\n",
    "    #         print(beam_results.shape, out_lens.shape)\n",
    "\n",
    "            if i%10==0:\n",
    "                print(\"Predict\", i*batchsize, end='\\r')\n",
    "\n",
    "            sequences.append(beam_results.detach())\n",
    "            sequence_lens.append(out_lens.detach())\n",
    "        write_submission(sequences, sequence_lens)\n",
    "    else:\n",
    "        for i, (x, y, x_len, y_len) in enumerate(loader):\n",
    "            x.to(device)\n",
    "#             y.to(device)\n",
    "#             x_len.to(device)\n",
    "#             y_len.to(device)\n",
    "\n",
    "            output, out_lens = model(x.to(device), x_len)\n",
    "#             output = output.permute(1,0,2)\n",
    "\n",
    "            log_string = 'output:' + str(output.shape) + str(output) + '\\n' + 'out_lens: ' + str(out_lens.shape) + str(out_lens)\n",
    "            log(log_file, log_string)\n",
    "\n",
    "            # probabilities, out_lens are passed to ctcdecoder instead of loss\n",
    "            beam_results, beam_scores, timesteps, out_lens = decoder.decode(output, out_lens)\n",
    "    #         print(beam_results.shape, out_lens.shape)\n",
    "\n",
    "#             if i%10==0:\n",
    "            print(\"Predict\", i*batchsize, end='\\r')\n",
    "\n",
    "            sequences.append(beam_results.detach())\n",
    "            sequence_lens.append(out_lens.detach())\n",
    "        \n",
    "    model.train()\n",
    "    model.predict = False\n",
    "    log_file.close()\n",
    "    return sequences, sequence_lens\n",
    "\n",
    "def write_submission(sequences, sequence_lens, sub_name='./submission9.csv'):\n",
    "    submission = csv.writer(open(sub_name, \"w\"))\n",
    "    submission.writerow(['id','label'])\n",
    "    Id=0\n",
    "    for batch in range(len(sequences)):\n",
    "        for i in range(len(sequences[batch])):\n",
    "            encoded_row = sequences[batch][i,0,:sequence_lens[batch][i,0]]\n",
    "            \n",
    "            row = ''\n",
    "            for phoneme in encoded_row:\n",
    "                row += PHONEME_MAP[phoneme.item()]\n",
    "            \n",
    "            submission.writerow([Id,row])\n",
    "            Id+=1\n",
    "            if Id%10 == 0:\n",
    "                print(\"Saved {} predictions\".format(Id), end='\\r')\n",
    "    print(\"Submission File COMPLETE\")\n",
    "    \n",
    "    return Id\n",
    "\n",
    "def levenshtein(a, b):\n",
    "    if not a: return len(b)\n",
    "    if not b: return len(a)\n",
    "    return min(levenshtein(a[1:], b[1:])+(a[0] != b[0]),\n",
    "               levenshtein(a[1:], b)+1,\n",
    "               levenshtein(a, b[1:])+1)\n",
    "\n",
    "def _levenshtein(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]\n",
    "\n",
    "# https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "def levenshtein_distance(model, loader):\n",
    "    model.eval()\n",
    "    model.predict = True\n",
    "    decoder = get_decoder(PHONEME_LIST)\n",
    "    log_file = open(\"levenshtein_dist_decoder_logs.txt\", \"w\")\n",
    "    sequences = []\n",
    "    sequence_lens = []\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y, x_len, y_len) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "    #         y.to(device)\n",
    "    #         x_len.to(device)\n",
    "    #         y_len.to(device)\n",
    "\n",
    "            output, out_lens = model(x, x_len)\n",
    "\n",
    "            output = output.to(torch.device(\"cpu\"))\n",
    "            del x\n",
    "\n",
    "            log_string = 'output:' + str(output.shape) + str(output) + '\\n' + 'out_lens: ' + str(out_lens.shape) + str(out_lens)\n",
    "            log(log_file, log_string)\n",
    "\n",
    "            # probabilities, out_lens are passed to ctcdecoder instead of loss\n",
    "            beam_results, beam_scores, timesteps, out_lens = decoder.decode(output.detach(), out_lens.detach())\n",
    "    #         print(beam_results.shape, out_lens.shape)\n",
    "    #         print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "            if i%10==0:\n",
    "                print(\"Levenshtein Predict\", i*batchsize, end='\\r')\n",
    "\n",
    "            sequences.append(beam_results.detach())\n",
    "            sequence_lens.append(out_lens.detach())\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "#     del x\n",
    "    \n",
    "    total_dist = 0\n",
    "    rows = []\n",
    "    Id=0\n",
    "    for batch in range(len(sequences)):\n",
    "        for i in range(len(sequences[batch])):\n",
    "            encoded_row = sequences[batch][i,0,:sequence_lens[batch][i,0]] #beam_results[0][0][:out_len[0][0]] TODO CHECK THIS\n",
    "            \n",
    "            row = ''\n",
    "            for phoneme in encoded_row:\n",
    "                row += PHONEME_MAP[phoneme.item()]\n",
    "            rows.append(row)\n",
    "            Id+=1\n",
    "            if Id%10 == 0:\n",
    "                print(\"Levenshtein Distance {}\".format(Id), end='\\r')\n",
    "    for row, val_row in zip(rows, VAL_ROWS):\n",
    "        total_dist += _levenshtein(row, val_row)\n",
    "    model.train()\n",
    "    model.predict = False\n",
    "    return total_dist/Id\n",
    "# decoded sequence\n",
    "# levenshtein distance\n",
    "# print(PHONEME_LIST, len(PHONEME_LIST))\n",
    "# predict(model, test_loader, PHONEME_LIST, test=True)\n",
    "# predict(model, test_loader, PHONEME_LIST\n",
    "# torch.cuda.empty_cache()\n",
    "# del x\n",
    "# del y\n",
    "# del output\n",
    "# del loss\n",
    "# levenshtein_distance(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Dist: 12.5368782161235 Loss: 0.41302626146464316 -----------------------------------------------0787\n",
      "\tImprovement: 987.4631217838765 | Percent Improvement: 98.74631217838765 %\n",
      "Time for epoch: 5710.455364704132\n",
      "   Running Best: Model_6_16 12.5368782161235 \n",
      "\n",
      "Epoch 1 Dist: 12.457118353344768 Loss: 0.36322463435215746 -----------------------------------------------11\n",
      "\tImprovement: 0.07975986277873126 | Percent Improvement: 0.6362019428102385 %\n",
      "Time for epoch: 5693.146910667419\n",
      "   Running Best: Model_6_17 12.457118353344768 \n",
      "\n",
      "Epoch 2 Dist: 12.433104631217839 Loss: 0.36163950561700187 -----------------------------------------------52\n",
      "\tImprovement: 0.024013722126928982 | Percent Improvement: 0.19277108433734386 %\n",
      "Time for epoch: 5694.483701705933\n",
      "   Running Best: Model_6_18 12.433104631217839 \n",
      "\n",
      "Epoch: 3 | Iteration: 5 | Projected Time Left 5491.771364927292 | Projected Time Total 5589.547709703445\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b3f7f979eca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         y = y.reshape(-1).to(device) # need to turn to row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#         print(output.shape, y.shape, x_len.shape, y_len.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# .unsqueeze(1) torch.log()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-1cbc4acb8469>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, X_lens)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mpacked_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mpacked_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 585\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_number = 16 #         <<<<<<<<<<<<<<<<<< CHANGE THIS TO 0 AFTER THIS MODEL\n",
    "prev_dist = 1000\n",
    "running_best = ['',10000]\n",
    "dist = 1000\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    ti = time()\n",
    "    cuda_mem_log = open(\"cuda_mem_log.txt\", \"w\")\n",
    "    model.train()\n",
    "    model.predict = False\n",
    "    for i, (x, y, x_len, y_len) in enumerate(train_loader):\n",
    "        _ti =time()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "#         x_len = x_len.to(device)\n",
    "#         y_len = y_len.to(device)\n",
    "\n",
    "#         to device all enumerated tupple\n",
    "#         y = y.reshape(-1).to(device) # need to turn to row\n",
    "\n",
    "        output, out_lens = model(x, x_len)\n",
    "#         print(output.shape, y.shape, x_len.shape, y_len.shape)\n",
    "        loss = criterion(output.permute(1,0,2), y, out_lens, y_len) # .unsqueeze(1) torch.log()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         # progress\n",
    "#         if i%10==0:\n",
    "        _tf = time()\n",
    "        print('Epoch:', epoch, '| Iteration:', i, '| Projected Time Left', ((21952//batchsize)-(i+1))*(_tf-_ti), '| Projected Time Total', ((21952//batchsize))*(_tf-_ti), end='\\r')\n",
    "\n",
    "    \n",
    "#     # Deallocate memory in GPU\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # validation\n",
    "    \n",
    "    \n",
    "    log(cuda_mem_log,torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "    cuda_mem_log.close()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    del x\n",
    "    del y\n",
    "    del output\n",
    "    \n",
    "    \n",
    "    dist = levenshtein_distance(model, val_loader)\n",
    "    print(\"Epoch\", epoch, \"Dist:\", dist, \"Loss:\", loss.item(), \"-----------------------------------------------\")\n",
    "    \n",
    "    del loss\n",
    "    \n",
    "    if prev_dist == 10000:\n",
    "        print(\"\\tImprovement:\", prev_dist-dist)\n",
    "    else:\n",
    "        print(\"\\tImprovement:\", prev_dist-dist, \"| Percent Improvement:\", 100*(prev_dist-dist)/prev_dist, '%')\n",
    "    # tracking running best AUC\n",
    "    if running_best[1]>dist:\n",
    "        running_best[0]='Model_' + str(RUN_NUMBER) + '_' + str(model_number)\n",
    "        running_best[1]=dist\n",
    "        \n",
    "    save_state(dist, running_best, model_number, model, train_loader_args, device, NUM_EPOCHS, learning_rate, optimizer, criterion)\n",
    "    model_number+=1\n",
    "\n",
    "    scheduler.step()\n",
    "    tf=time()\n",
    "    print(\"Time for epoch:\", tf-ti)\n",
    "    print('   Running Best:', *running_best,'\\n')\n",
    "\n",
    "    prev_dist = dist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 46        |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    7428 MB |   11052 MB |  183250 GB |  183242 GB |\n",
      "|       from large pool |    7426 MB |   11050 MB |  183158 GB |  183151 GB |\n",
      "|       from small pool |       2 MB |      23 MB |      91 GB |      91 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    7428 MB |   11052 MB |  183250 GB |  183242 GB |\n",
      "|       from large pool |    7426 MB |   11050 MB |  183158 GB |  183151 GB |\n",
      "|       from small pool |       2 MB |      23 MB |      91 GB |      91 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    9752 MB |   12850 MB |  305036 MB |  295284 MB |\n",
      "|       from large pool |    9748 MB |   12830 MB |  304310 MB |  294562 MB |\n",
      "|       from small pool |       4 MB |      26 MB |     726 MB |     722 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    2323 MB |    7058 MB |  182208 GB |  182205 GB |\n",
      "|       from large pool |    2321 MB |    7057 MB |  182082 GB |  182080 GB |\n",
      "|       from small pool |       1 MB |      15 MB |     125 GB |     125 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      94    |     162    |    1173 K  |    1173 K  |\n",
      "|       from large pool |      48    |      82    |     742 K  |     742 K  |\n",
      "|       from small pool |      46    |      92    |     431 K  |     431 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      94    |     162    |    1173 K  |    1173 K  |\n",
      "|       from large pool |      48    |      82    |     742 K  |     742 K  |\n",
      "|       from small pool |      46    |      92    |     431 K  |     431 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      19    |      34    |     623    |     604    |\n",
      "|       from large pool |      17    |      26    |     260    |     243    |\n",
      "|       from small pool |       2    |      13    |     363    |     361    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      21    |      38    |  439992    |  439971    |\n",
      "|       from large pool |      17    |      22    |  323758    |  323741    |\n",
      "|       from small pool |       4    |      21    |  116234    |  116230    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# for p in model.parameters():\n",
    "#     print(sys.getsizeof(p))\n",
    "# print(output.shape, y.shape, x_len.unsqueeze(1), y_len.shape)\n",
    "# print(\"Epoch\", epoch, \"Dist:\", dist)\n",
    "# torch.cuda.device_of(next(model.parameters()))\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "# cuda_mem_log = open(\"cuda_mem_log.txt\", \"w\")\n",
    "# log(cuda_mem_log,torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "# cuda_mem_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_state(10000, running_best, -1, model, train_loader_args, device, NUM_EPOCHS, learning_rate, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2332"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For AWS:  Need to `pip install python-Levenshtein` while in activated pytorch environment\n",
    "# https://github.com/ztane/python-Levenshtein/\n",
    "# from Levenshtein import distance\n",
    "# distance('abcd','aqcde')\n",
    "len(VAL_ROWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission File COMPLETE\n",
      "WOOO!\n"
     ]
    }
   ],
   "source": [
    "predict(model, test_loader, PHONEME_LIST, test=True)\n",
    "print(\"WOOO!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_5 \n",
    "class Model(Module):\n",
    "    def __init__(self, out_vocab, embed_size, hidden_size, in_channel=13):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1d = Conv1d(in_channel, embed_size, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.lstm1 = LSTM(embed_size, hidden_size, bidirectional=True)\n",
    "        self.lstm2 = LSTM(hidden_size*2, hidden_size, bidirectional=True)\n",
    "        self.lstm3 = LSTM(hidden_size*2, hidden_size, bidirectional=True)\n",
    "        self.lstm4 = LSTM(hidden_size*2, hidden_size, bidirectional=True)\n",
    "        self.predict = False\n",
    "        \n",
    "#         self.linear1 = Linear(hidden_size*2, hidden_size*2)\n",
    "#         self.relu1 = ReLU()\n",
    "#         self.linear2 = Linear(hidden_size*2, out_vocab+1)\n",
    "        \n",
    "        self.linear3 = Linear(hidden_size*2, out_vocab+1)\n",
    "        \n",
    "    def forward(self, X, X_lens):\n",
    "        X = self.conv1d(X) # CNN requires (batch_size, embedding_size, timesteps)\n",
    "\n",
    "        X = X.permute(0,2,1)\n",
    "        packed_X = pack_padded_sequence(X, X_lens, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        packed_X = self.lstm1(packed_X)[0] # LSTM requires (timesteps, batch_size, embedding_size)\n",
    "        packed_X = self.lstm2(packed_X)[0]\n",
    "        packed_X = self.lstm3(packed_X)[0]\n",
    "        packed_X = self.lstm4(packed_X)[0]\n",
    "        \n",
    "        X, out_lens = pad_packed_sequence(packed_X)\n",
    "        \n",
    "#         X = self.linear1(X.permute(1,0,2))\n",
    "#         X = self.relu1(X)\n",
    "#         out = self.linear2(X).softmax(2) # B x timesteps x 42 log_softmax(2)\n",
    "        \n",
    "        X = self.linear3(X.permute(1,0,2))\n",
    "        \n",
    "#         if self.predict:\n",
    "#             print(\"SOFTMAX\")\n",
    "#         out = X.softmax(2)\n",
    "#         else:\n",
    "#             print(\"LOG\")\n",
    "        out = X.log_softmax(2)\n",
    "        \n",
    "        return out, out_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad/pack sequence\n",
    "class BasicBlock(Module):\n",
    "    def __init__(self, out_vocab, embed_size, hidden_size, in_channel=13):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1d = Conv1d(in_channel, embed_size, kernel_size=3, stride=1, padding=1, bias=False) # do I need this?\n",
    "        self.lstm = LSTM(embed_size, hidden_size, bidirectional=True)\n",
    "        \n",
    "    def forward(self, X, lengths):\n",
    "        X = self.conv1d(X) # CNN requires (batch_size, embedding_size, timesteps)\n",
    "        \n",
    "        X = X.permute(0,2,1)\n",
    "        \n",
    "        packed_X = pack_padded_sequence(X, lengths, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        packed_out = self.lstm(packed_X)[0] # LSTM requires (timesteps, batch_size, embedding_size)\n",
    "        \n",
    "        out, out_lens = pad_packed_sequence(packed_out)\n",
    "        \n",
    "        return out, out_lens\n",
    "\n",
    "class Model(Module):\n",
    "    def __init__(self, out_vocab, embed_size, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.block1 = BasicBlock(out_vocab, embed_size, hidden_size)\n",
    "        self.block2 = BasicBlock(out_vocab, embed_size, hidden_size, in_channel=hidden_size*2)\n",
    "        self.block3 = BasicBlock(out_vocab, embed_size, hidden_size, in_channel=hidden_size*2)\n",
    "        \n",
    "        self.linear1 = Linear(hidden_size*2, hidden_size*2)\n",
    "        self.relu1 = ReLU()\n",
    "        self.dropout = Dropout(0.1)\n",
    "        self.linear2 = Linear(hidden_size*2, out_vocab+1)\n",
    "        \n",
    "    def forward(self, X, lengths):\n",
    "        X, X_lens = self.block1(X, lengths)\n",
    "#         print(X.shape)\n",
    "        X, X_lens = self.block2(X.permute(1,2,0), X_lens)\n",
    "#         print(X.shape)\n",
    "        X, out_lens = self.block3(X.permute(1,2,0), X_lens)\n",
    "#         print(X.shape)\n",
    "        X = self.linear1(X.permute(1,0,2)).log_softmax(2)\n",
    "        X = self.relu1(X)\n",
    "        X = self.dropout(X)\n",
    "#         print(X.shape)\n",
    "        X = self.linear2(X).log_softmax(2)\n",
    "        return X, out_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self, out_vocab, embed_size, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1d = Conv1d(13, embed_size, kernel_size=3, stride=1, padding=1, bias=False) # do I need this?\n",
    "        self.lstm = LSTM(embed_size, hidden_size, bidirectional=False)\n",
    "        self.linear = Linear(hidden_size, out_vocab+1) # hidden_size*2? if bidirectional??\n",
    "\n",
    "    def forward(self, X, lengths):\n",
    "        # May want this in collate\n",
    "        # X = pad_sequence(X)\n",
    "        # print(X.permute(1,2,0).shape) # [32, 13, 1720]\n",
    "        # X = X.permute(1,2,0)\n",
    "\n",
    "        # print(\"in:\", X.shape) # CNN requires (batch_size, embedding_size, timesteps)  TODO: double check\n",
    "        X = self.conv1d(X)\n",
    "        # print(\"after Conv1d:\", X.shape) # lstm requires (timesteps, batch_size, embedding_size)  TODO: double check \n",
    "        X = X.permute(0,2,1)\n",
    "        packed_X = pack_padded_sequence(X, lengths, batch_first=True, enforce_sorted=False)\n",
    "        # print(\"packed:\", packed_X.data.shape)\n",
    "        packed_out = self.lstm(packed_X)[0] # why [0]? check output\n",
    "        out, out_lens = pad_packed_sequence(packed_out)\n",
    "        out = self.linear(out).log_softmax(2)\n",
    "        # print(\"Eureka!\")\n",
    "        return out, out_lens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}