{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcU2C_VaVFlV"
   },
   "source": [
    "# Homework 1 Part 2\n",
    "### Kinori Rosnow (krosnow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KwfNIaPpVKgC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# context for each data point\n",
    "CONTEXT = 40\n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-VPkOu9JGTnu"
   },
   "source": [
    "## Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with small map - getitem() O(1) - memory O(n), but storing only end indices\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X_path, Y_path):\n",
    "        self.X = np.load(X_path, allow_pickle=True)\n",
    "        self.Y = np.load(Y_path, allow_pickle=True)\n",
    "        self.height = CONTEXT*2+1\n",
    "        \n",
    "        self.sample_index = []\n",
    "        length=0\n",
    "        for i in range(len(self.Y)):\n",
    "            length+=self.Y[i].shape[0]\n",
    "            self.sample_index.append(length-1)\n",
    "        self.length = length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    # binary search through data which leverages self.sample_index to track end indices of each sample\n",
    "    def search(self, index):\n",
    "        start = 0\n",
    "        end = len(self.Y)-1\n",
    "        i = (start+end)//2\n",
    "        while end - start >= 0 :\n",
    "            # END CASE\n",
    "            if i>0:\n",
    "                if index <= self.sample_index[i] and index > self.sample_index[i-1]:\n",
    "                    in_sample_index = index - self.sample_index[i-1] - 1\n",
    "                    sample = i\n",
    "                    return sample, in_sample_index\n",
    "            else:\n",
    "                if index <= self.sample_index[i]:\n",
    "                    in_sample_index = index\n",
    "                    sample = i\n",
    "                    return sample, in_sample_index\n",
    "\n",
    "            # CONTINUE SEARCH\n",
    "            if index > self.sample_index[i]:\n",
    "                start = i+1\n",
    "                i = (start + end)//2\n",
    "            elif index < self.sample_index[i]:\n",
    "                end = i\n",
    "                i = (start + end)//2\n",
    "            else:\n",
    "                raise Exception(\"unaccounted case\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample, i = self.search(index)\n",
    "        \n",
    "        # pad\n",
    "        if i<CONTEXT:\n",
    "            X = self.X[sample][:i+CONTEXT+1]\n",
    "            X = np.pad(X, pad_width=((self.height-X.shape[0],0),(0,0)), mode='constant', constant_values=0.)\n",
    "        elif i >= self.Y[sample].shape[0] - CONTEXT:\n",
    "            X = self.X[sample][i-CONTEXT:]\n",
    "            X = np.pad(X, pad_width=((0,self.height-X.shape[0]),(0,0)), mode='constant', constant_values=0.)\n",
    "        else:\n",
    "            X = self.X[sample][i-CONTEXT:i+CONTEXT+1]\n",
    "\n",
    "        Y = np.array(self.Y[sample][i])\n",
    "        \n",
    "        X=torch.flatten(torch.Tensor(X))\n",
    "        Y=torch.from_numpy(Y)\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZa0n_EuGRB4"
   },
   "source": [
    "## Data Loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "ck47HEl5GOfP",
    "outputId": "85722c24-7ff3-4df5-f803-ee25c9ec2485"
   },
   "outputs": [],
   "source": [
    "num_workers = 4 if cuda else 0\n",
    "batchsize = 256 if cuda else 64\n",
    "print(\"Loading Validation Set\")\n",
    "# Validation Set\n",
    "val_X_path = './dev.npy'\n",
    "val_Y_path = './dev_labels.npy'\n",
    "val_dataset = MyDataset(val_X_path, val_Y_path)\n",
    "\n",
    "val_loader_args = dict(shuffle=False, batch_size=batchsize, num_workers=num_workers, pin_memory=True) if cuda else dict(shuffle=False, batch_size=batchsize)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, **val_loader_args)\n",
    "print(\"Validation Set Loaded\")\n",
    "\n",
    "print(\"Loading Training Set\")\n",
    "# Training Set\n",
    "train_X_path = './train.npy' \n",
    "train_Y_path = './train_labels.npy' \n",
    "train_dataset = MyDataset(train_X_path, train_Y_path)\n",
    "\n",
    "droplast=False\n",
    "if len(train_dataset)%batchsize==1:\n",
    "    print(\"Dropping last because last batch of size:\", len(train_dataset)%batchsize)\n",
    "    droplast=True\n",
    "train_loader_args = dict(shuffle=True, batch_size=batchsize, num_workers=num_workers, pin_memory=True, drop_last=droplast) if cuda else dict(shuffle=True, batch_size=batchsize, drop_last=droplast) #TODO: shuffle=True\n",
    "\n",
    "train_loader = DataLoader(train_dataset, **train_loader_args)\n",
    "print(\"Training Set Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PpIn21pQIN2l"
   },
   "source": [
    "## Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "rzIqX7ozIMiz",
    "outputId": "6589d69b-3ef3-4482-b390-d074159fbd3e"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Module # from .module import Module\n",
    "from torch.nn import Linear, BatchNorm1d, Sequential, ReLU, CrossEntropyLoss, Sigmoid # if I import this way do I not need to add nn.?\n",
    "\n",
    "IN_OUT = (CONTEXT*2+1)*13\n",
    "class Model(Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # look up feed forward architecture - batch norm, deeper\n",
    "        # In must be the input size, output can be increased - output of prev = input of next\n",
    "        layers = [\n",
    "                  Linear(IN_OUT, int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), 346)\n",
    "        ]\n",
    "        \n",
    "        self.layers = Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "  \n",
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHkS08mJOztO"
   },
   "source": [
    "## More Tuning Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "NEv2ZMVkN-hj",
    "outputId": "065972a4-f043-4e80-eaac-29562b950f47"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "RUN_NUMBER = 14  # THIS WILL DEFINE PATH OF WHERE THE MODEL IS SAVED\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "NUM_EPOCHS = 5 # originally set to 30, but stopped at 5 because it was overfitting\n",
    "learning_rate = 1e-3\n",
    "mile_stones = [4] #,8,12,16,20,24]\n",
    "gamma = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=mile_stones, gamma=gamma)\n",
    "criterion = CrossEntropyLoss()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation function\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    total = len(val_dataset)\n",
    "    num_correct = 0\n",
    "    for i, (x,y) in enumerate(val_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.reshape(-1).to(device)\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        out = out.to(\"cpu\")\n",
    "        y = y.to(\"cpu\")\n",
    "\n",
    "        batch_predictions = np.argmax(out.data, axis=1)\n",
    "        num_correct += (batch_predictions == y).sum()\n",
    "    accuracy = num_correct.item() / total\n",
    "    model.train()\n",
    "    return accuracy\n",
    "\n",
    "def save_state(accuracy, model_number, model, train_loader_args, device, NUM_EPOCHS, learning_rate, optimizer, criterion):\n",
    "    path = './hw1p2_models/model_' + str(RUN_NUMBER) + '_'+str(model_number)\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    torch.save(model, path+'/model.pt')\n",
    "    # write parameter tracking file just in case I need them\n",
    "    parameter_file = open(path+'/hyperparameters.txt', 'w')\n",
    "    parameter_file.write('Accuracy:\\n' + str(accuracy))\n",
    "    parameter_file.write('\\nContext:\\n' + str(CONTEXT))\n",
    "    parameter_file.write('\\nModel:\\n' + str(model))\n",
    "    parameter_file.write('\\ntrain_loader_args:\\n' + str(train_loader_args))\n",
    "    parameter_file.write('\\nDevice:\\n' + str(device))\n",
    "    parameter_file.write('\\nNUM_EPOCHS:\\n' + str(NUM_EPOCHS))\n",
    "    parameter_file.write('\\nLearning Rate:\\n' + str(learning_rate))\n",
    "    parameter_file.write('\\nOptimizer:\\n' + str(optimizer))\n",
    "    parameter_file.write('\\nCriterion:\\n' + str(criterion))\n",
    "    parameter_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2QHrGoReOVc-"
   },
   "source": [
    "## Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "9vIEIIyoOUPm",
    "outputId": "a42ddd08-3282-40b7-8e02-e120144e6c78"
   },
   "outputs": [],
   "source": [
    "# toggle to train so save gradients\n",
    "val_accuracies=[]\n",
    "model.train()\n",
    "model_number=0\n",
    "prev_acc = 0\n",
    "running_max = ['',0.]\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (x,y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.reshape(-1).to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # progress\n",
    "        if i%1000==0:\n",
    "            print('Epoch:', epoch, '| Iteration:', i, end='\\r')\n",
    "\n",
    "    # validation\n",
    "    accuracy = validate(model, val_loader)\n",
    "    val_accuracies.append(accuracy)\n",
    "    \n",
    "    # save progress\n",
    "    save_state(accuracy, model_number, model, train_loader_args, device, NUM_EPOCHS, learning_rate, optimizer, criterion)\n",
    "    model_number+=1\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    # performance update\n",
    "    print(\"Epoch\", epoch, \"Accuracy:\", accuracy)\n",
    "    if prev_acc == 0:\n",
    "        print(\"\\tImprovement:\", accuracy-prev_acc)\n",
    "    else:\n",
    "        print(\"\\tImprovement:\", accuracy-prev_acc, \"| Percent Improvement:\", 100*(accuracy-prev_acc)/prev_acc, '%')\n",
    "    if running_max[1]<accuracy:\n",
    "        running_max[0]='Model_' + str(RUN_NUMBER) + '_' + str(epoch)\n",
    "        running_max[1]=accuracy\n",
    "    print('   Running Max:', *running_max,'\\n')\n",
    "    \n",
    "    prev_acc = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Loading and Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module # from .module import Module\n",
    "from torch.nn import Linear, BatchNorm1d, Sequential, ReLU, CrossEntropyLoss\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# context for each data point\n",
    "cuda=True \n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "num_workers = 4 if cuda else 0\n",
    "batchsize = 256 if cuda else 64\n",
    "CONTEXT = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_OUT = (CONTEXT*2+1)*13\n",
    "class Model(Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [\n",
    "                  Linear(IN_OUT, int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), 346)\n",
    "        ]\n",
    "        \n",
    "        self.layers = Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Model Load\n",
    "model_path = 'hw1p2_models/model_7_4/model.pt'\n",
    "model = torch.load(model_path)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with small map - getitem() O(1) - memory O(n), but storing only end indices\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "  # heavy processing here because only done once\n",
    "    def __init__(self, X_path):\n",
    "        self.X = np.load(X_path, allow_pickle=True)\n",
    "        \n",
    "        self.height = CONTEXT*2+1\n",
    "        \n",
    "        self.sample_index = []\n",
    "        length=0\n",
    "        for i in range(len(self.X)):\n",
    "            length+=self.X[i].shape[0]\n",
    "            self.sample_index.append(length-1)\n",
    "        self.length = length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def search(self, index):\n",
    "        start = 0\n",
    "        end = len(self.X)-1\n",
    "        i = (start+end)//2\n",
    "        while end - start >= 0 :\n",
    "            # END CASE\n",
    "            if i>0:\n",
    "                if index <= self.sample_index[i] and index > self.sample_index[i-1]:\n",
    "                    in_sample_index = index - self.sample_index[i-1] - 1\n",
    "                    sample = i\n",
    "                    return sample, in_sample_index\n",
    "            else:\n",
    "                if index <= self.sample_index[i]:\n",
    "                    in_sample_index = index\n",
    "                    sample = i\n",
    "                    return sample, in_sample_index\n",
    "\n",
    "            # CONTINUE SEARCH\n",
    "            if index > self.sample_index[i]:\n",
    "                start = i+1\n",
    "                i = (start + end)//2\n",
    "            elif index < self.sample_index[i]:\n",
    "                end = i\n",
    "                i = (start + end)//2\n",
    "            else:\n",
    "                raise Exception(\"unaccounted case\")\n",
    "\n",
    "    # keep this simple/quick because run many times\n",
    "    def __getitem__(self, index):\n",
    "        sample, i = self.search(index)\n",
    "        \n",
    "        if i<CONTEXT:\n",
    "            X = self.X[sample][:i+CONTEXT+1]\n",
    "            X = np.pad(X, pad_width=((self.height-X.shape[0],0),(0,0)), mode='constant', constant_values=0.)\n",
    "        elif i >= self.X[sample].shape[0] - CONTEXT:\n",
    "            X = self.X[sample][i-CONTEXT:]\n",
    "            X = np.pad(X, pad_width=((0,self.height-X.shape[0]),(0,0)), mode='constant', constant_values=0.)\n",
    "        else:\n",
    "            X = self.X[sample][i-CONTEXT:i+CONTEXT+1]\n",
    "\n",
    "        X=torch.flatten(torch.Tensor(X))\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4 if cuda else 0\n",
    "batchsize = 256 if cuda else 64\n",
    "print(\"Loading Test Set\")\n",
    "# Validation Set\n",
    "test_X_path = './test.npy'\n",
    "test_dataset = TestDataset(test_X_path)\n",
    "\n",
    "test_loader_args = dict(shuffle=False, batch_size=batchsize, num_workers=num_workers, pin_memory=True) if cuda else dict(shuffle=False, batch_size=batchsize)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, **test_loader_args)\n",
    "print(\"Test Set Loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "sub_name = './submission5.csv' #<====================CHANGE THIS EVERY TIME=============<<<<<<<<\n",
    "\n",
    "def predict(model, test_loader, sub_name):\n",
    "    submission = csv.writer(open(sub_name, \"w\"))\n",
    "    submission.writerow(['id','label'])\n",
    "    \n",
    "    total = 0\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (x) in enumerate(test_loader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        out = out.to(\"cpu\")\n",
    "        \n",
    "        batch = torch.argmax(out, dim=1)\n",
    "        for item in range(batch.shape[0]):\n",
    "            total+=1\n",
    "            submission.writerow([str(i*batchsize+item),str(batch[item].item())])\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(\"Saved {} predicitons\".format((i+1)*batchsize), end='\\r')\n",
    "    return total\n",
    "\n",
    "T=predict(model, test_loader, sub_name)\n",
    "print(\"{} Predictions COMPLETE\".format(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested Model Architectures (with decent results)\n",
    "### Model_3_6, 4_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module): # Model_3_6(CONTEXT=20), Model_4_8(CONTEXT=30)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [\n",
    "                  Linear(IN_OUT, IN_OUT),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(IN_OUT),\n",
    "                  Linear(IN_OUT, IN_OUT),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(IN_OUT),\n",
    "                  Linear(IN_OUT, IN_OUT),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(IN_OUT),\n",
    "                  Linear(IN_OUT, IN_OUT),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(IN_OUT),\n",
    "                  Linear(IN_OUT, 346)\n",
    "        ]\n",
    "\n",
    "        self.layers = Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_5_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        layers = [\n",
    "                  Linear(IN_OUT, IN_OUT),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(IN_OUT),\n",
    "                  Linear(IN_OUT, IN_OUT),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(IN_OUT),\n",
    "                  Linear(IN_OUT, IN_OUT),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(IN_OUT),\n",
    "                  Linear(IN_OUT, IN_OUT),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(IN_OUT),\n",
    "                  Linear(IN_OUT, IN_OUT),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(IN_OUT),\n",
    "                  Linear(IN_OUT, 346)\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_6_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "                  Linear(IN_OUT, int(IN_OUT*1.2)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.2)),\n",
    "                  Linear(int(IN_OUT*1.2), int(IN_OUT*1.2)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.2)),\n",
    "                  Linear(int(IN_OUT*1.2), int(IN_OUT*1.2)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.2)),\n",
    "                  Linear(int(IN_OUT*1.2), int(IN_OUT*1.2)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.2)),\n",
    "                  Linear(int(IN_OUT*1.2), IN_OUT),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(IN_OUT),\n",
    "                  Linear(IN_OUT, IN_OUT),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(IN_OUT),\n",
    "                  Linear(IN_OUT, 346)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_7_4 (Best Model), Model_8_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "                  Linear(IN_OUT, int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), int(IN_OUT*1.4)),\n",
    "                  ReLU(),\n",
    "                  BatchNorm1d(int(IN_OUT*1.4)),\n",
    "                  Linear(int(IN_OUT*1.4), 346)\n",
    "        ]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw1p2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
